{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1zivcq_lccXDGzF9ojRQ30kA-uCFD5EG5","authorship_tag":"ABX9TyNclajm7/s7HRIiyN8qINQX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Data Extraction for Blackcoffer Assignment"],"metadata":{"id":"dm2hWr7FNK0t"}},{"cell_type":"code","source":["#Mounting the google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ww_jY0y1V8zK","executionInfo":{"status":"ok","timestamp":1693830921873,"user_tz":-330,"elapsed":12871,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}},"outputId":"6fb15ee0-69d8-492a-8ecf-7f1aecd20e5e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cziQvORQLFsB","executionInfo":{"status":"ok","timestamp":1693830927794,"user_tz":-330,"elapsed":3976,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}},"outputId":"638a3e31-415d-455d-ceb5-800265290618"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["#Importing packages\n","\n","import requests\n","import os\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import re"]},{"cell_type":"code","source":["#Importing input file\n","df=pd.read_csv('/content/Input (1).csv')[['URL_ID','URL']]"],"metadata":{"id":"AyJEuZ4S-61b","executionInfo":{"status":"ok","timestamp":1693830947366,"user_tz":-330,"elapsed":429,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1FSeVhGO9pJ","executionInfo":{"status":"ok","timestamp":1693830953402,"user_tz":-330,"elapsed":420,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}},"outputId":"4e7dbc5b-0d27-43ea-f169-68e31796f83f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["114"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"u60Mai2APhDQ","executionInfo":{"status":"ok","timestamp":1693830954912,"user_tz":-330,"elapsed":14,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}},"outputId":"20639d80-4b96-485a-8c5d-50b3cb8bcb1d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      URL_ID                                                URL\n","0      123.0  https://insights.blackcoffer.com/rise-of-telem...\n","1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...\n","2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...\n","3     4321.0  https://insights.blackcoffer.com/rise-of-telem...\n","4      432.0  https://insights.blackcoffer.com/rise-of-telem...\n","..       ...                                                ...\n","109  50921.0  https://insights.blackcoffer.com/coronavirus-i...\n","110  51382.8  https://insights.blackcoffer.com/coronavirus-i...\n","111  51844.6  https://insights.blackcoffer.com/what-are-the-...\n","112  52306.4  https://insights.blackcoffer.com/marketing-dri...\n","113  52768.2  https://insights.blackcoffer.com/continued-dem...\n","\n","[114 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-1fba12bb-9954-41ce-9077-55f989bc140d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL_ID</th>\n","      <th>URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>123.0</td>\n","      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>321.0</td>\n","      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2345.0</td>\n","      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4321.0</td>\n","      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>432.0</td>\n","      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>50921.0</td>\n","      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>51382.8</td>\n","      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>51844.6</td>\n","      <td>https://insights.blackcoffer.com/what-are-the-...</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>52306.4</td>\n","      <td>https://insights.blackcoffer.com/marketing-dri...</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>52768.2</td>\n","      <td>https://insights.blackcoffer.com/continued-dem...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>114 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fba12bb-9954-41ce-9077-55f989bc140d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1fba12bb-9954-41ce-9077-55f989bc140d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1fba12bb-9954-41ce-9077-55f989bc140d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-eccefb60-3bfe-4920-974d-1ee7084d3988\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eccefb60-3bfe-4920-974d-1ee7084d3988')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-eccefb60-3bfe-4920-974d-1ee7084d3988 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Looping through each row in the dataframe\n","for index, row in df.iterrows():\n","  url = row['URL']\n","  url_id = row['URL_ID']\n","\n","  # Making a request to url\n","  header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n","  try:\n","    response = requests.get(url,headers=header)\n","  except:\n","    print(\"can't get response of {}\".format(url_id))\n","\n","  #Creating a beautifulsoup object\n","  try:\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","  except:\n","    print(\"can't get page of {}\".format(url_id))\n","  #Finding title\n","  try:\n","    title = soup.find('h1').get_text()\n","  except:\n","    print(\"can't get title of {}\".format(url_id))\n","    continue\n","\n","   #Finding text\n","  article = \"\"\n","  try:\n","    for p in soup.find_all('p'):\n","      article += p.get_text()\n","  except:\n","    print(\"can't get text of {}\".format(url_id))\n","\n","  #Writing the obtained Title and Text to the file\n","  file_name = '/content/drive/MyDrive/mywork/title_text.txt' + str(url_id) + '.txt'\n","  with open(file_name, 'w') as file:\n","    file.write(title + '\\n' + article)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BK_pBDTVq-1t","executionInfo":{"status":"ok","timestamp":1693831048036,"user_tz":-330,"elapsed":89809,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}},"outputId":"36654624-41a7-4b03-e93c-fde172c0a237"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["can't get title of 11668.0\n","can't get title of 17671.4\n"]}]},{"cell_type":"code","source":["# Directories\n","text_dir = \"/content/drive/MyDrive/mywork/dataextraction/title_text\"\n","stopwords_dir = \"/content/drive/MyDrive/mywork/StopWords\"\n","sentiment_dir = \"/content/drive/MyDrive/mywork/MasterDictionary\"\n","\n","#Loading and storing all the Stop Words from the stopwords directory to the set variable\n","stop_words = set()\n","for files in os.listdir(stopwords_dir):\n","  with open(os.path.join(stopwords_dir,files),'r',encoding='ISO-8859-1') as f:\n","    stop_words.update(set(f.read().splitlines()))\n","\n","#Loading all the text files from the directory and storing in a list\n","docs = []\n","for text_file in os.listdir(text_dir):\n","  with open(os.path.join(text_dir,text_file),'r') as f:\n","    text = f.read()\n","#Tokenizing the given text file\n","    words = word_tokenize(text)\n","#Removing the stop words from the tokens\n","    filtered_text = [word for word in words if word.lower() not in stop_words]\n","#Adding each filtered token of each file into a list\n","    docs.append(filtered_text)\n","\n","#Storing positive, Negative words from the directory\n","pos=set()\n","neg=set()\n","\n","for files in os.listdir(sentiment_dir):\n","  if files =='positive-words.txt':\n","    with open(os.path.join(sentiment_dir,files),'r',encoding='ISO-8859-1') as f:\n","      pos.update(f.read().splitlines())\n","  else:\n","    with open(os.path.join(sentiment_dir,files),'r',encoding='ISO-8859-1') as f:\n","      neg.update(f.read().splitlines())\n","\n","#Collect and calculating the positive and negative words score from each file\n","positive_words = []\n","Negative_words =[]\n","positive_score = []\n","negative_score = []\n","polarity_score = []\n","subjectivity_score = []\n","\n","#Iterating through the list of docs\n","for i in range(len(docs)):\n","  positive_words.append([word for word in docs[i] if word.lower() in pos])\n","  Negative_words.append([word for word in docs[i] if word.lower() in neg])\n","  positive_score.append(len(positive_words[i]))\n","  negative_score.append(len(Negative_words[i]))\n","  polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n","  subjectivity_score.append((positive_score[i] + negative_score[i]) / ((len(docs[i])) + 0.000001))\n"],"metadata":{"id":"19G7PQtrsOoj","executionInfo":{"status":"ok","timestamp":1693831062018,"user_tz":-330,"elapsed":3027,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Average Sentence Length = the number of words / the number of sentences\n","# Percentage of Complex words = the number of complex words / the number of words\n","# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n","\n","import os\n","import nltk\n","from nltk.corpus import stopwords\n","\n","avg_sentence_length = []\n","Percentage_of_Complex_words  =  []\n","Fog_Index = []\n","complex_word_count =  []\n","avg_syllable_word_count =[]\n","\n","stopwords_set = set(stopwords.words('english'))\n","\n","def measure(file):\n","  with open(os.path.join(text_dir, file),'r') as f:\n","    text = f.read()\n","# Removing punctuations\n","    text = re.sub(r'[^\\w\\s.]','',text)\n","# Spliting into sentences\n","    sentences = text.split('.')\n","# Total number of sentences in a file\n","    num_sentences = len(sentences)\n","# Total words in the file\n","    words = [word  for word in text.split() if word.lower() not in stopwords ]\n","    num_words = len(words)\n","\n","# Complex words are words in the text that contain more than two syllables.\n","    complex_words = []\n","    for word in words:\n","      vowels = 'aeiou'\n","      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n","      if syllable_count_word > 2:\n","        complex_words.append(word)\n","\n","# Syllable Count Per Word\n","# We count the number of Syllables in each word of the text by counting the vowels present in each word.\n","#  We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable.\n","    syllable_count = 0\n","    syllable_words =[]\n","    for word in words:\n","      if word.endswith('es'):\n","        word = word[:-2]\n","      elif word.endswith('ed'):\n","        word = word[:-2]\n","      vowels = 'aeiou'\n","      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n","      if syllable_count_word >= 1:\n","        syllable_words.append(word)\n","        syllable_count += syllable_count_word\n","\n","      try:\n","          avg_sentence_length = num_words / num_sentences\n","      except ZeroDivisionError:\n","          avg_sentence_len = 0  # Handle the case where num_sentences is zero\n","\n","      try:\n","          avg_syllable_word_count = syllable_count / len(syllable_words)\n","      except ZeroDivisionError:\n","          avg_syllable_word_count = 0  # Handle the case where len(syllable_words) is zero\n","\n","      try:\n","          Percent_Complex_words = len(complex_words) / num_words\n","      except ZeroDivisionError:\n","          Percent_Complex_words = 0  # Handle the case where num_words is zero\n","\n","      Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n","\n","\n","\n","\n","      return avg_sentence_length, Percent_Complex_words, Fog_Index, len(complex_words),avg_syllable_word_count\n","\n","  # iterate through each file or doc\n","for file in os.listdir(text_dir):\n","    result = measure(file)\n","    if result is not None:\n","        x, y, z, a, b = result\n","        avg_sentence_length.append(x)\n","        Percentage_of_Complex_words.append(y)\n","        Fog_Index.append(z)\n","        complex_word_count.append(a)\n","        avg_syllable_word_count.append(b)\n","\n","    else:\n","        print(f\"Measurement couldn't be performed for file: {file}\")"],"metadata":{"id":"rAyscqZ6sqEz","executionInfo":{"status":"ok","timestamp":1693831065503,"user_tz":-330,"elapsed":799,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Word Count and Average Word Length Sum of the total number of characters in each word/Total number of words\n","# We count the total cleaned words present in the text by\n","# Removing the stop words (using stopwords class of nltk package).\n","# Removing any punctuations like ? ! , . from the word before counting.\n","\n","def cleaned_words(file):\n","  with open(os.path.join(text_dir,file), 'r') as f:\n","    text = f.read()\n","    text = re.sub(r'[^\\w\\s]', '' , text)\n","    words = [word  for word in text.split() if word.lower() not in stopwords]\n","    length = sum(len(word) for word in words)\n","    average_word_length = length / len(words)\n","  return len(words),average_word_length\n","\n","word_count = []\n","average_word_length = []\n","for file in os.listdir(text_dir):\n","  x, y = cleaned_words(file)\n","  word_count.append(x)\n","  average_word_length.append(y)\n","\n","# To calculate Personal Pronouns mentioned in the text, we use regex to find\n","# The counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken\n","#  so that the country name \"US\" is not included in the list.\n","def count_personal_pronouns(file):\n","  with open(os.path.join(text_dir,file), 'r') as f:\n","    text = f.read()\n","    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n","    count = 0\n","    for pronoun in personal_pronouns:\n","      count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text)) # \\b is used to match word boundaries\n","  return count\n","\n","pp_count = []\n","for file in os.listdir(text_dir):\n","  x = count_personal_pronouns(file)\n","  pp_count.append(x)"],"metadata":{"id":"_vSSafEbFzOz","executionInfo":{"status":"ok","timestamp":1693831072486,"user_tz":-330,"elapsed":681,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","output_df = pd.read_excel('/content/Output Data Structure (2).xlsx')\n","\n","output_df.drop([44-37,57-37,144-37], axis = 0, inplace=True)\n","\n","variables = [positive_score,\n","            negative_score,\n","            polarity_score,\n","            subjectivity_score,\n","            avg_sentence_length,\n","            Percentage_of_Complex_words,\n","            Fog_Index,\n","            avg_sentence_length,\n","            complex_word_count,\n","            word_count,\n","            avg_syllable_word_count,\n","            pp_count,\n","            average_word_length]\n","\n","# Initializing the DataFrame with the appropriate number of columns\n","output_df = pd.DataFrame(columns=['positive_score', 'negative_score', 'polarity_score', 'subjectivity_score',\n","                                  'avg_sentence_length','Percentage_of_Complex_words','Fog_Index','avg_sentence_length','complex_word_count',\n","                                  'word_count','avg_syllable_word_count','pp_count','average_word_length'])\n","\n","# Assigning the values from variables to specific columns\n","for i, var in enumerate(variables):\n","    column_name = output_df.columns[i]\n","    output_df[column_name] = var\n","\n","output_df.to_excel('Output_Data.xlsx')\n"],"metadata":{"id":"Ypoh9LScqINV","executionInfo":{"status":"ok","timestamp":1693831706467,"user_tz":-330,"elapsed":532,"user":{"displayName":"Saumya Tripathi","userId":"17333167565075269424"}}},"execution_count":19,"outputs":[]}]}